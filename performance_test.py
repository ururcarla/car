#!/usr/bin/env python3
"""
æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼šæ‰“åŒ…ROIåˆ°å¤§å›¾æ¨ç† vs æ‰¹é‡æ¨ç†ROI
æ”¯æŒ GPU æ¨ç†å’Œ KITTI æ•°æ®é›†

ä½¿ç”¨æ–¹æ³•:
    1. é»˜è®¤ä½¿ç”¨ GPU å’Œéšæœºæ•°æ®:
       python performance_test.py
    
    2. ä½¿ç”¨ GPU å’Œ KITTI æ•°æ®é›†:
       python performance_test.py --kitti-path "C:/path/to/kitti/dataset"
    
    3. å¼ºåˆ¶ä½¿ç”¨ CPU:
       python performance_test.py --cpu
    
    4. ä½¿ç”¨éšæœºæ•°æ®ï¼ˆä¸ä½¿ç”¨ KITTIï¼‰:
       python performance_test.py --no-kitti
    
    5. CPU + KITTI æ•°æ®é›†:
       python performance_test.py --cpu --kitti-path "C:/path/to/kitti/dataset"

å‚æ•°è¯´æ˜:
    --gpu         ä½¿ç”¨ GPU è¿›è¡Œæ¨ç†ï¼ˆé»˜è®¤ï¼‰
    --cpu         å¼ºåˆ¶ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†
    --kitti-path  KITTI æ•°æ®é›†è·¯å¾„
    --kitti-limit é™åˆ¶åŠ è½½çš„ KITTI å›¾åƒæ•°é‡ï¼ˆé»˜è®¤: 16ï¼‰
    --no-kitti    ä¸ä½¿ç”¨ KITTI æ•°æ®é›†ï¼Œä½¿ç”¨éšæœºæ•°æ®
"""
import time
import numpy as np
import cv2
import torch
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from roi_canvas_demo import (
    ROICanvasDemo, 
    pack_rois_fixed_canvas, 
    batch_inference_rois,
    extract_rois_from_frames,
    remap_batch_detections_to_original,
    remap_tile_dets_to_original,
    assign_dets_to_tiles,
    ROIMapping,
    USE_BATCH_PROCESSING,
    USE_BEV_FUSION,
    ROI_BATCH_SIZE,
    CANVAS_W,
    CANVAS_H
)

class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, use_gpu: bool = True, kitti_path: Optional[str] = None, kitti_limit: int = 16):
        """
        åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•å™¨
        
        Args:
            use_gpu: æ˜¯å¦ä½¿ç”¨ GPU è¿›è¡Œæ¨ç†
            kitti_path: KITTI æ•°æ®é›†è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.use_gpu = use_gpu
        self.device = 0 if use_gpu and torch.cuda.is_available() else 'cpu'
        self.kitti_path = Path(kitti_path) if kitti_path else None
        self.kitti_limit = max(1, int(kitti_limit)) if kitti_path else 0
        
        # æ£€æŸ¥ GPU å¯ç”¨æ€§
        if use_gpu:
            if torch.cuda.is_available():
                print(f"âœ… ä½¿ç”¨ GPU: {torch.cuda.get_device_name(0)}")
                print(f"   CUDA ç‰ˆæœ¬: {torch.version.cuda}")
                print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
            else:
                print("âš ï¸  GPU ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU")
                self.device = 'cpu'
        else:
            print("â„¹ï¸  ä½¿ç”¨ CPU æ¨¡å¼")
        
        # åˆå§‹åŒ–æ¼”ç¤ºå¯¹è±¡
        self.demo = ROICanvasDemo(['front', 'left', 'right', 'rear'], img_size=(640, 480))
        
        # åŠ è½½ KITTI æ•°æ®é›†ï¼ˆå¦‚æœæä¾›ï¼‰
        self.kitti_images = []
        if self.kitti_path and self.kitti_path.exists():
            self._load_kitti_dataset()
    
    def _load_kitti_dataset(self):
        """åŠ è½½ KITTI æ•°æ®é›†å›¾åƒ"""
        print(f"\nğŸ“‚ åŠ è½½ KITTI æ•°æ®é›†: {self.kitti_path}")
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„å›¾åƒè·¯å¾„
        possible_paths = [
            self.kitti_path,
            self.kitti_path / 'image_2',
            self.kitti_path / 'training' / 'image_2',
            self.kitti_path / 'valid',
        ]
        
        for path in possible_paths:
            if path.exists():
                # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
                image_files = list(path.glob('*.png')) + list(path.glob('*.jpg'))
                if image_files:
                    limit = self.kitti_limit if self.kitti_limit > 0 else 16
                    self.kitti_images = sorted(image_files)[:limit]
                    print(f"   âœ… æ‰¾åˆ° {len(self.kitti_images)} å¼ å›¾åƒ")
                    print(f"   è·¯å¾„: {path}")
                    return
        
        print(f"   âš ï¸  æœªæ‰¾åˆ° KITTI å›¾åƒï¼Œå°†ä½¿ç”¨éšæœºæµ‹è¯•æ•°æ®")
        
    def create_test_data(self, num_rois: int = 8, use_kitti: bool = True) -> Tuple[Dict[str, np.ndarray], List[Tuple[str, int, int, int, int]]]:
        """
        åˆ›å»ºæµ‹è¯•æ•°æ®
        
        Args:
            num_rois: ROI æ•°é‡
            use_kitti: æ˜¯å¦ä½¿ç”¨ KITTI æ•°æ®é›†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        
        Returns:
            frames: ç›¸æœºå¸§å­—å…¸
            roi_coords: ROI åæ ‡åˆ—è¡¨
        """
        # åˆ›å»ºæµ‹è¯•å¸§
        frames = {}
        cameras = ['front', 'left', 'right', 'rear']
        
        # å¦‚æœæœ‰ KITTI æ•°æ®é›†ä¸”é€‰æ‹©ä½¿ç”¨ï¼Œåˆ™åŠ è½½çœŸå®å›¾åƒ
        if use_kitti and self.kitti_images:
            print(f"   ä½¿ç”¨ KITTI æ•°æ®é›†å›¾åƒ")
            for i, cam_name in enumerate(cameras):
                # å¾ªç¯ä½¿ç”¨ KITTI å›¾åƒ
                img_idx = i % len(self.kitti_images)
                img_path = self.kitti_images[img_idx]
                frame = cv2.imread(str(img_path))
                
                if frame is not None:
                    # è°ƒæ•´åˆ°ç›®æ ‡å¤§å°
                    frame = cv2.resize(frame, (640, 480))
                    frames[cam_name] = frame
                else:
                    # å¦‚æœåŠ è½½å¤±è´¥ï¼Œä½¿ç”¨éšæœºæ•°æ®
                    frame = self._create_random_frame()
                    frames[cam_name] = frame
        else:
            # ä½¿ç”¨éšæœºæµ‹è¯•å›¾åƒ
            print(f"   ä½¿ç”¨éšæœºæµ‹è¯•æ•°æ®")
            for cam_name in cameras:
                frame = self._create_random_frame()
                frames[cam_name] = frame
        
        # åˆ›å»ºæ¨¡æ‹ŸROIåæ ‡
        roi_coords = []
        for i in range(num_rois):
            cam_name = cameras[i % len(cameras)]
            # éšæœºç”ŸæˆROIåæ ‡
            x = np.random.randint(50, 500)
            y = np.random.randint(50, 350)
            w = np.random.randint(80, 150)
            h = np.random.randint(80, 150)
            roi_coords.append((cam_name, x, y, w, h))
        
        return frames, roi_coords
    
    def _create_random_frame(self) -> np.ndarray:
        """åˆ›å»ºéšæœºæµ‹è¯•å¸§"""
        frame = np.random.randint(50, 200, (480, 640, 3), dtype=np.uint8)
        # æ·»åŠ ä¸€äº›çº¹ç†
        for i in range(0, 480, 30):
            cv2.line(frame, (0, i), (640, i), (100, 100, 100), 1)
        return frame
    
    def test_canvas_processing(self, frames: Dict[str, np.ndarray], 
                              roi_coords: List[Tuple[str, int, int, int, int]], 
                              num_runs: int = 10) -> Dict[str, float]:
        """æµ‹è¯•ç”»å¸ƒå¤„ç†æ€§èƒ½"""
        print(f"\n=== æµ‹è¯•ç”»å¸ƒå¤„ç†æ€§èƒ½ ({num_runs} æ¬¡è¿è¡Œ) ===")
        
        times = []
        roi_extraction_times = []
        canvas_packing_times = []
        inference_times = []
        remapping_times = []
        
        for run in range(num_runs):
            # 1. æå–ROI
            start = time.perf_counter()
            roi_items = []
            for cam_name, x, y, w, h in roi_coords:
                if cam_name in frames:
                    frame = frames[cam_name]
                    roi = frame[y:y+h, x:x+w]
                    roi_items.append((cam_name, frame, (x, y, w, h)))
            roi_extraction_time = (time.perf_counter() - start) * 1000
            roi_extraction_times.append(roi_extraction_time)
            
            # 2. æ‰“åŒ…åˆ°ç”»å¸ƒ
            start = time.perf_counter()
            canvas, mappings = pack_rois_fixed_canvas(roi_items, CANVAS_W, CANVAS_H)
            canvas_packing_time = (time.perf_counter() - start) * 1000
            canvas_packing_times.append(canvas_packing_time)
            
            # 3. ç”»å¸ƒæ¨ç†ï¼ˆä½¿ç”¨ GPUï¼‰
            start = time.perf_counter()
            res = self.demo.model.predict(canvas, verbose=False, device=self.device)[0]
            inference_time = (time.perf_counter() - start) * 1000
            inference_times.append(inference_time)
            
            # 4. ç»“æœæ˜ å°„
            start = time.perf_counter()
            if res.boxes.shape[0] == 0:
                canvas_dets = np.empty((0, 6), dtype=np.float32)
            else:
                xyxy = res.boxes.xyxy.cpu().numpy().astype(np.float32)
                conf = res.boxes.conf.cpu().numpy().astype(np.float32).reshape(-1, 1)
                cls = res.boxes.cls.cpu().numpy().astype(np.float32).reshape(-1, 1)
                canvas_dets = np.hstack((xyxy, conf, cls))
            
            buckets = assign_dets_to_tiles(canvas_dets, mappings)
            remapped = remap_tile_dets_to_original(buckets, mappings)
            remapping_time = (time.perf_counter() - start) * 1000
            remapping_times.append(remapping_time)
            
            total_time = roi_extraction_time + canvas_packing_time + inference_time + remapping_time
            times.append(total_time)
            
            if run == 0:  # ç¬¬ä¸€æ¬¡è¿è¡Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                print(f"  ROIæå–æ—¶é—´: {roi_extraction_time:.2f} ms")
                print(f"  ç”»å¸ƒæ‰“åŒ…æ—¶é—´: {canvas_packing_time:.2f} ms")
                print(f"  æ¨ç†æ—¶é—´: {inference_time:.2f} ms")
                print(f"  ç»“æœæ˜ å°„æ—¶é—´: {remapping_time:.2f} ms")
                print(f"  æ€»æ—¶é—´: {total_time:.2f} ms")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_avg': np.mean(times),
            'total_std': np.std(times),
            'total_min': np.min(times),
            'total_max': np.max(times),
            'roi_extraction_avg': np.mean(roi_extraction_times),
            'canvas_packing_avg': np.mean(canvas_packing_times),
            'inference_avg': np.mean(inference_times),
            'remapping_avg': np.mean(remapping_times)
        }
        
        print(f"\nç”»å¸ƒå¤„ç†ç»Ÿè®¡ (ROIæ•°é‡: {len(roi_coords)}):")
        print(f"  æ€»æ—¶é—´: {stats['total_avg']:.2f} Â± {stats['total_std']:.2f} ms")
        print(f"  æœ€å¿«: {stats['total_min']:.2f} ms, æœ€æ…¢: {stats['total_max']:.2f} ms")
        print(f"  ROIæå–: {stats['roi_extraction_avg']:.2f} ms")
        print(f"  ç”»å¸ƒæ‰“åŒ…: {stats['canvas_packing_avg']:.2f} ms")
        print(f"  æ¨ç†: {stats['inference_avg']:.2f} ms")
        print(f"  ç»“æœæ˜ å°„: {stats['remapping_avg']:.2f} ms")
        
        return stats
    
    def test_batch_processing(self, frames: Dict[str, np.ndarray], 
                             roi_coords: List[Tuple[str, int, int, int, int]], 
                             num_runs: int = 10) -> Dict[str, float]:
        """æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½"""
        print(f"\n=== æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½ ({num_runs} æ¬¡è¿è¡Œ) ===")
        
        times = []
        roi_extraction_times = []
        roi_resize_times = []
        inference_times = []
        remapping_times = []
        
        for run in range(num_runs):
            # 1. æå–å’Œè°ƒæ•´ROI
            start = time.perf_counter()
            roi_items = extract_rois_from_frames(frames, roi_coords)
            roi_extraction_time = (time.perf_counter() - start) * 1000
            roi_extraction_times.append(roi_extraction_time)
            
            if not roi_items:
                print("  è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„ROI")
                continue
            
            # 2. æ‰¹é‡æ¨ç†ï¼ˆä½¿ç”¨ GPUï¼‰
            start = time.perf_counter()
            roi_batch = [item[1] for item in roi_items]
            
            # è¿‡æ»¤æœ‰æ•ˆROI
            valid_rois = []
            for roi in roi_batch:
                if roi.size > 0 and roi.shape[0] > 0 and roi.shape[1] > 0:
                    valid_rois.append(roi)
            
            if not valid_rois:
                print("  è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„ROIè¿›è¡Œæ¨ç†")
                continue
            
            # ä½¿ç”¨ GPU è¿›è¡Œæ‰¹é‡æ¨ç†
            batch_array = np.stack(valid_rois, axis=0)
            results = self.demo.model.predict(batch_array, verbose=False, device=self.device)
            
            # å¤„ç†æ‰¹é‡æ£€æµ‹ç»“æœ
            batch_detections = []
            for result in results:
                if result.boxes.shape[0] == 0:
                    batch_detections.append(np.empty((0, 6), dtype=np.float32))
                else:
                    xyxy = result.boxes.xyxy.cpu().numpy().astype(np.float32)
                    conf = result.boxes.conf.cpu().numpy().astype(np.float32).reshape(-1, 1)
                    cls = result.boxes.cls.cpu().numpy().astype(np.float32).reshape(-1, 1)
                    batch_detections.append(np.hstack((xyxy, conf, cls)))
            
            inference_time = (time.perf_counter() - start) * 1000
            inference_times.append(inference_time)
            
            # 3. ç»“æœæ˜ å°„
            start = time.perf_counter()
            remapped_dets = remap_batch_detections_to_original(batch_detections, roi_items)
            remapping_time = (time.perf_counter() - start) * 1000
            remapping_times.append(remapping_time)
            
            total_time = roi_extraction_time + inference_time + remapping_time
            times.append(total_time)
            
            if run == 0:  # ç¬¬ä¸€æ¬¡è¿è¡Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                print(f"  ROIæå–è°ƒæ•´æ—¶é—´: {roi_extraction_time:.2f} ms")
                print(f"  æ‰¹é‡æ¨ç†æ—¶é—´: {inference_time:.2f} ms")
                print(f"  ç»“æœæ˜ å°„æ—¶é—´: {remapping_time:.2f} ms")
                print(f"  æ€»æ—¶é—´: {total_time:.2f} ms")
        
        if not times:
            print("  é”™è¯¯: æ²¡æœ‰æˆåŠŸå®Œæˆä»»ä½•è¿è¡Œ")
            return {}
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_avg': np.mean(times),
            'total_std': np.std(times),
            'total_min': np.min(times),
            'total_max': np.max(times),
            'roi_extraction_avg': np.mean(roi_extraction_times),
            'inference_avg': np.mean(inference_times),
            'remapping_avg': np.mean(remapping_times)
        }
        
        print(f"\næ‰¹é‡å¤„ç†ç»Ÿè®¡ (ROIæ•°é‡: {len(roi_coords)}):")
        print(f"  æ€»æ—¶é—´: {stats['total_avg']:.2f} Â± {stats['total_std']:.2f} ms")
        print(f"  æœ€å¿«: {stats['total_min']:.2f} ms, æœ€æ…¢: {stats['total_max']:.2f} ms")
        print(f"  ROIæå–è°ƒæ•´: {stats['roi_extraction_avg']:.2f} ms")
        print(f"  æ‰¹é‡æ¨ç†: {stats['inference_avg']:.2f} ms")
        print(f"  ç»“æœæ˜ å°„: {stats['remapping_avg']:.2f} ms")
        
        return stats
    
    def compare_performance(self, canvas_stats: Dict[str, float], 
                          batch_stats: Dict[str, float], 
                          roi_count: int):
        """å¯¹æ¯”æ€§èƒ½ç»“æœ"""
        print(f"\n{'='*60}")
        print(f"æ€§èƒ½å¯¹æ¯”ç»“æœ (ROIæ•°é‡: {roi_count})")
        print(f"{'='*60}")
        
        if not canvas_stats or not batch_stats:
            print("é”™è¯¯: æ— æ³•è¿›è¡Œå¯¹æ¯”ï¼ŒæŸä¸ªæµ‹è¯•å¤±è´¥")
            return
        
        # æ€»æ—¶é—´å¯¹æ¯”
        canvas_total = canvas_stats['total_avg']
        batch_total = batch_stats['total_avg']
        speedup = canvas_total / batch_total if batch_total > 0 else float('inf')
        
        print(f"\nğŸ“Š æ€»å¤„ç†æ—¶é—´å¯¹æ¯”:")
        print(f"  ç”»å¸ƒå¤„ç†: {canvas_total:.2f} Â± {canvas_stats['total_std']:.2f} ms")
        print(f"  æ‰¹é‡å¤„ç†: {batch_total:.2f} Â± {batch_stats['total_std']:.2f} ms")
        print(f"  æ€§èƒ½æå‡: {speedup:.2f}x {'(æ‰¹é‡æ›´å¿«)' if speedup > 1 else '(ç”»å¸ƒæ›´å¿«)'}")
        
        # å„é˜¶æ®µæ—¶é—´å¯¹æ¯”
        print(f"\nğŸ” å„é˜¶æ®µæ—¶é—´å¯¹æ¯”:")
        print(f"  ROIå¤„ç†:")
        print(f"    ç”»å¸ƒ: {canvas_stats['roi_extraction_avg']:.2f} ms")
        print(f"    æ‰¹é‡: {batch_stats['roi_extraction_avg']:.2f} ms")
        
        print(f"  æ¨ç†:")
        print(f"    ç”»å¸ƒ: {canvas_stats['inference_avg']:.2f} ms")
        print(f"    æ‰¹é‡: {batch_stats['inference_avg']:.2f} ms")
        
        print(f"  ç»“æœæ˜ å°„:")
        print(f"    ç”»å¸ƒ: {canvas_stats['remapping_avg']:.2f} ms")
        print(f"    æ‰¹é‡: {batch_stats['remapping_avg']:.2f} ms")
        
        # ç”»å¸ƒå¤„ç†é¢å¤–å¼€é”€
        canvas_extra = canvas_stats['canvas_packing_avg']
        print(f"  ç”»å¸ƒæ‰“åŒ…å¼€é”€: {canvas_extra:.2f} ms")
        
        # æ•ˆç‡åˆ†æ
        print(f"\nğŸ’¡ æ•ˆç‡åˆ†æ:")
        if speedup > 1.2:
            print(f"  âœ… æ‰¹é‡å¤„ç†æ˜æ˜¾æ›´å¿« ({speedup:.2f}x)")
        elif speedup > 0.8:
            print(f"  âš–ï¸  ä¸¤ç§æ–¹æ³•æ€§èƒ½ç›¸è¿‘ ({speedup:.2f}x)")
        else:
            print(f"  âŒ ç”»å¸ƒå¤„ç†æ›´å¿« ({speedup:.2f}x)")
        
        # å†…å­˜ä½¿ç”¨åˆ†æ
        print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨åˆ†æ:")
        canvas_memory = CANVAS_W * CANVAS_H * 3  # ç”»å¸ƒå¤§å°
        batch_memory = roi_count * ROI_BATCH_SIZE * ROI_BATCH_SIZE * 3  # æ‰¹é‡å¤§å°
        print(f"  ç”»å¸ƒå¤„ç†å†…å­˜: {canvas_memory / 1024  / 1024:.2f} MB")
        print(f"  æ‰¹é‡å¤„ç†å†…å­˜: {batch_memory / 1024 / 1024:.2f} MB")
        
        if batch_memory > canvas_memory:
            print(f"  æ‰¹é‡å¤„ç†ä½¿ç”¨æ›´å¤šå†…å­˜ ({batch_memory/canvas_memory:.2f}x)")
        else:
            print(f"  ç”»å¸ƒå¤„ç†ä½¿ç”¨æ›´å¤šå†…å­˜ ({canvas_memory/batch_memory:.2f}x)")
    
    def run_comprehensive_test(self, use_kitti: bool = True):
        """
        è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•
        
        Args:
            use_kitti: æ˜¯å¦ä½¿ç”¨ KITTI æ•°æ®é›†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        """
        print("ğŸš€ å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
        print("="*60)
        print(f"   è®¾å¤‡: {'GPU' if self.device == 0 else 'CPU'}")
        print(f"   æ•°æ®æº: {'KITTI æ•°æ®é›†' if use_kitti and self.kitti_images else 'éšæœºæ•°æ®'}")
        
        # æµ‹è¯•ä¸åŒçš„ROIæ•°é‡
        roi_counts = [4, 8, 12, 16]
        num_runs = 5  # å‡å°‘è¿è¡Œæ¬¡æ•°ä»¥èŠ‚çœæ—¶é—´
        
        all_results = []
        
        for roi_count in roi_counts:
            print(f"\nğŸ”¬ æµ‹è¯• ROIæ•°é‡: {roi_count}")
            print("-" * 40)
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            frames, roi_coords = self.create_test_data(roi_count, use_kitti=use_kitti)
            
            # æµ‹è¯•ç”»å¸ƒå¤„ç†
            canvas_stats = self.test_canvas_processing(frames, roi_coords, num_runs)
            
            # æµ‹è¯•æ‰¹é‡å¤„ç†
            batch_stats = self.test_batch_processing(frames, roi_coords, num_runs)
            
            # å¯¹æ¯”ç»“æœ
            self.compare_performance(canvas_stats, batch_stats, roi_count)
            
            all_results.append({
                'roi_count': roi_count,
                'canvas_stats': canvas_stats,
                'batch_stats': batch_stats
            })
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report(all_results)
    
    def generate_summary_report(self, results: List[Dict]):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print("ğŸ“‹ æ€§èƒ½æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print(f"{'='*60}")
        
        print(f"\né…ç½®ä¿¡æ¯:")
        print(f"  ç”»å¸ƒå¤§å°: {CANVAS_W}x{CANVAS_H}")
        print(f"  ROIæ‰¹é‡å¤§å°: {ROI_BATCH_SIZE}x{ROI_BATCH_SIZE}")
        print(f"  æµ‹è¯•è¿è¡Œæ¬¡æ•°: 5")
        
        print(f"\nğŸ“Š ä¸åŒROIæ•°é‡ä¸‹çš„æ€§èƒ½å¯¹æ¯”:")
        print(f"{'ROIæ•°é‡':<8} {'ç”»å¸ƒ(ms)':<12} {'æ‰¹é‡(ms)':<12} {'æå‡å€æ•°':<10} {'æ¨èæ–¹æ³•'}")
        print("-" * 60)
        
        for result in results:
            roi_count = result['roi_count']
            canvas_avg = result['canvas_stats']['total_avg']
            batch_avg = result['batch_stats']['total_avg']
            speedup = canvas_avg / batch_avg if batch_avg > 0 else 0
            
            if speedup > 1.2:
                recommendation = "æ‰¹é‡å¤„ç†"
            elif speedup > 0.8:
                recommendation = "ç›¸è¿‘"
            else:
                recommendation = "ç”»å¸ƒå¤„ç†"
            
            print(f"{roi_count:<8} {canvas_avg:<12.2f} {batch_avg:<12.2f} {speedup:<10.2f} {recommendation}")
        
        print(f"\nğŸ’¡ å»ºè®®:")
        print(f"  - å°‘é‡ROI (<8): ç”»å¸ƒå¤„ç†å¯èƒ½æ›´ç¨³å®š")
        print(f"  - ä¸­ç­‰ROI (8-12): æ ¹æ®å…·ä½“åœºæ™¯é€‰æ‹©")
        print(f"  - å¤§é‡ROI (>12): æ‰¹é‡å¤„ç†å¯èƒ½æ›´é«˜æ•ˆ")
        print(f"  - å†…å­˜é™åˆ¶: è€ƒè™‘ä½¿ç”¨ç”»å¸ƒå¤„ç†")
        print(f"  - ç¨³å®šæ€§ä¼˜å…ˆ: æ¨èç”»å¸ƒå¤„ç†")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ROI å¤„ç†æ€§èƒ½å¯¹æ¯”æµ‹è¯• (æ”¯æŒ GPU å’Œ KITTI æ•°æ®é›†)')
    parser.add_argument('--gpu', action='store_true', default=True, 
                        help='ä½¿ç”¨ GPU è¿›è¡Œæ¨ç† (é»˜è®¤: True)')
    parser.add_argument('--cpu', action='store_true', 
                        help='å¼ºåˆ¶ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†')
    parser.add_argument('--kitti-path', type=str, default=None,
                        help='KITTI æ•°æ®é›†è·¯å¾„ (å¯é€‰)')
    parser.add_argument('--kitti-limit', type=int, default=16,
                        help='é™åˆ¶åŠ è½½çš„ KITTI å›¾åƒæ•°é‡ (é»˜è®¤: 16)')
    parser.add_argument('--no-kitti', action='store_true',
                        help='ä¸ä½¿ç”¨ KITTI æ•°æ®é›†ï¼Œä½¿ç”¨éšæœºæ•°æ®')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ˜¯å¦ä½¿ç”¨ GPU
    use_gpu = args.gpu and not args.cpu
    
    print("ğŸ¯ ROIå¤„ç†æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = PerformanceTester(use_gpu=use_gpu, kitti_path=args.kitti_path, kitti_limit=args.kitti_limit)
    
    try:
        # è¿è¡Œç»¼åˆæµ‹è¯•
        use_kitti = not args.no_kitti
        tester.run_comprehensive_test(use_kitti=use_kitti)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ!")

if __name__ == '__main__':
    main()
